{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install bi-lstm-crf\n! wget https://github.com/kobkrit/datasets/raw/main/AIFORTHAI-LST20Corpus.tar.gz\n! tar -xvzf AIFORTHAI-LST20Corpus.tar.gz","metadata":{"id":"zxQPHxerABCB","outputId":"5e06b176-a30b-41fb-ab1e-77887ce04787","execution":{"iopub.status.busy":"2022-04-12T09:27:14.927512Z","iopub.execute_input":"2022-04-12T09:27:14.928263Z","iopub.status.idle":"2022-04-12T09:27:28.066227Z","shell.execute_reply.started":"2022-04-12T09:27:14.928145Z","shell.execute_reply":"2022-04-12T09:27:28.065412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets -qq","metadata":{"id":"hVQjmmj3gTJ_","outputId":"1e5c4bcf-705a-4ded-c987-0b8ee6989a04","execution":{"iopub.status.busy":"2022-04-12T09:27:28.068353Z","iopub.execute_input":"2022-04-12T09:27:28.069037Z","iopub.status.idle":"2022-04-12T09:27:36.565497Z","shell.execute_reply.started":"2022-04-12T09:27:28.068996Z","shell.execute_reply":"2022-04-12T09:27:36.564536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cell 0\nfrom datasets import load_dataset\nimport pandas as pd\nfrom torch.utils.data import DataLoader,Dataset\n\nimport torch as T\nimport torch.nn as N\nimport torch.optim as O\n\nimport random\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\nimport os","metadata":{"id":"-2XxGVc4f4qP","execution":{"iopub.status.busy":"2022-04-12T09:27:36.567272Z","iopub.execute_input":"2022-04-12T09:27:36.567556Z","iopub.status.idle":"2022-04-12T09:27:38.621469Z","shell.execute_reply.started":"2022-04-12T09:27:36.567522Z","shell.execute_reply":"2022-04-12T09:27:38.62076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst20 = load_dataset(\"lst20\", data_dir=\"LST20_Corpus\")\nlst20","metadata":{"id":"8niOKpXSgOyV","outputId":"d1fd1a72-4edb-451e-d078-b1f874f26cbb","execution":{"iopub.status.busy":"2022-04-12T09:27:38.623296Z","iopub.execute_input":"2022-04-12T09:27:38.623557Z","iopub.status.idle":"2022-04-12T09:28:28.827155Z","shell.execute_reply.started":"2022-04-12T09:27:38.62352Z","shell.execute_reply":"2022-04-12T09:28:28.826485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(os.listdir(\"/content/LST20_Corpus/test\"))","metadata":{"id":"wouY-w34grPW","outputId":"9ff79aa9-4164-4de0-ad18-db72db546dd8","execution":{"iopub.status.busy":"2022-04-12T09:28:28.828256Z","iopub.execute_input":"2022-04-12T09:28:28.829115Z","iopub.status.idle":"2022-04-12T09:28:28.832786Z","shell.execute_reply.started":"2022-04-12T09:28:28.829066Z","shell.execute_reply":"2022-04-12T09:28:28.831953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = pd.DataFrame(lst20['train'])[['tokens']]\ndata_df","metadata":{"id":"ioB0sZz7hdhX","outputId":"9ff7f56c-8fbb-41d3-daaf-df23cfa829d5","execution":{"iopub.status.busy":"2022-04-12T09:28:28.834105Z","iopub.execute_input":"2022-04-12T09:28:28.834528Z","iopub.status.idle":"2022-04-12T09:28:45.215971Z","shell.execute_reply.started":"2022-04-12T09:28:28.83449Z","shell.execute_reply":"2022-04-12T09:28:45.215215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_val = pd.DataFrame(lst20['validation'])\ndata_test = pd.DataFrame(lst20['test'])","metadata":{"id":"x4XP9xg82zxV","execution":{"iopub.status.busy":"2022-04-12T09:28:45.220592Z","iopub.execute_input":"2022-04-12T09:28:45.223093Z","iopub.status.idle":"2022-04-12T09:28:48.164103Z","shell.execute_reply.started":"2022-04-12T09:28:45.222987Z","shell.execute_reply":"2022-04-12T09:28:48.163388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df['tokens'] = data_df.tokens.apply(lambda x:'|'.join(x).replace('_',' ').split('|'))\ndata_df['len'] = data_df.tokens.apply(len)\ndata_df['lenchar'] = data_df.tokens.apply(lambda x:len(''.join(x)))\ndata_df","metadata":{"id":"yVeMCxwuh5lG","outputId":"162a04f4-7e11-4a07-a135-9e77498990e2","execution":{"iopub.status.busy":"2022-04-12T09:28:48.165424Z","iopub.execute_input":"2022-04-12T09:28:48.165697Z","iopub.status.idle":"2022-04-12T09:28:48.928086Z","shell.execute_reply.started":"2022-04-12T09:28:48.165663Z","shell.execute_reply":"2022-04-12T09:28:48.927368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = data_df[data_df.len > 10].reset_index()\ndata_df","metadata":{"id":"O1xDoqt2kJA6","outputId":"94b75def-6521-4be7-bed1-3559a5451c16","execution":{"iopub.status.busy":"2022-04-12T09:28:48.929487Z","iopub.execute_input":"2022-04-12T09:28:48.929954Z","iopub.status.idle":"2022-04-12T09:28:48.955153Z","shell.execute_reply.started":"2022-04-12T09:28:48.929918Z","shell.execute_reply":"2022-04-12T09:28:48.954392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cell 7\n\"\"\"char2idx = {None: 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, '+': 12, ',': 13, '-': 14, '.': 15, '/': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ':': 27, ';': 28, '=': 29, '?': 30, '@': 31, 'A': 32, 'B': 33, 'C': 34, 'D': 35, 'E': 36, 'F': 37, 'G': 38, 'H': 39, 'I': 40, 'J': 41, 'K': 42, 'L': 43, 'M': 44, 'N': 45, 'O': 46, 'P': 47, 'Q': 48, 'R': 49, 'S': 50, 'T': 51, 'U': 52, 'V': 53, 'W': 54, 'X': 55, 'Y': 56, 'Z': 57, '[': 58, ']': 59, 'a': 60, 'b': 61, 'c': 62, 'd': 63, 'e': 64, 'f': 65, 'g': 66, 'h': 67, 'i': 68, 'j': 69, 'k': 70, 'l': 71, 'm': 72, 'n': 73, 'o': 74, 'p': 75, 'q': 76, 'r': 77, 's': 78, 't': 79, 'u': 80, 'v': 81, 'w': 82, 'x': 83, 'y': 84, 'z': 85, '\\xa0': 86, '®': 87, 'é': 88, 'ü': 89, 'ก': 90, 'ข': 91, 'ฃ': 92, 'ค': 93, 'ฅ': 94, 'ฆ': 95, 'ง': 96, 'จ': 97, 'ฉ': 98, 'ช': 99, 'ซ': 100, 'ฌ': 101, 'ญ': 102, 'ฎ': 103, 'ฏ': 104, 'ฐ': 105, 'ฑ': 106, 'ฒ': 107, 'ณ': 108, 'ด': 109, 'ต': 110, 'ถ': 111, 'ท': 112, 'ธ': 113, 'น': 114, 'บ': 115, 'ป': 116, 'ผ': 117, 'ฝ': 118, 'พ': 119, 'ฟ': 120, 'ภ': 121, 'ม': 122, 'ย': 123, 'ร': 124, 'ฤ': 125, 'ล': 126, 'ฦ': 127, 'ว': 128, 'ศ': 129, 'ษ': 130, 'ส': 131, 'ห': 132, 'ฬ': 133, 'อ': 134, 'ฮ': 135, 'ฯ': 136, 'ะ': 137, 'ั': 138, 'า': 139, 'ำ': 140, 'ิ': 141, 'ี': 142, 'ึ': 143, 'ื': 144, 'ุ': 145, 'ู': 146, 'ฺ': 147, '฿': 148, 'เ': 149, 'แ': 150, 'โ': 151, 'ใ': 152, 'ไ': 153, 'ๅ': 154, 'ๆ': 155, '็': 156, '่': 157, '้': 158, '๊': 159, '๋': 160, '์': 161, 'ํ': 162, '๎': 163, '๏': 164, '๐': 165, '๑': 166, '๒': 167, '๓': 168, '๔': 169, '๕': 170, '๖': 171, '๗': 172, '๘': 173, '๙': 174, '๚': 175, '๛': 176, '\\u200e': 177, '–': 178, '—': 179, '‘': 180, '’': 181, '…': 182, '™': 183}\n\"\"\"\n\n#cell 8\nidx2char = [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '®', 'é', 'ü', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ', 'ล', 'ฦ', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', '฿', 'เ', 'แ', 'โ', 'ใ', 'ไ', 'ๅ', 'ๆ', '็', '่', '้', '๊', '๋', '์', 'ํ', '๎', '๏', '๐', '๑', '๒', '๓', '๔', '๕', '๖', '๗', '๘', '๙', '๚', '๛', '\\u200e', '–', '—', '‘', '’', '…', '™']\n\nchar2idx={v:k for k,v in enumerate(idx2char)}\n","metadata":{"id":"BMw_OJAgktDH","execution":{"iopub.status.busy":"2022-04-12T09:28:48.95821Z","iopub.execute_input":"2022-04-12T09:28:48.958402Z","iopub.status.idle":"2022-04-12T09:28:48.972821Z","shell.execute_reply.started":"2022-04-12T09:28:48.958378Z","shell.execute_reply":"2022-04-12T09:28:48.970694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cell 9\ndef str2idxseq(charseq):\n    idxseq = []\n    for char in charseq:\n        char = char.lower()\n        idxseq.append(char2idx.get(char,0))\n        \"\"\"if char in char2idx:\n            idxseq.append(char2idx[char])\n        else:\n            idxseq.append(char2idx[None])\"\"\"\n    return idxseq\ncuter_idxseq = str2idxseq('สวัสดีครับ')\nprint(cuter_idxseq)","metadata":{"id":"u0u2Hmmpkxg6","outputId":"7d74a5ce-760f-4426-d7aa-ae4fe58368cd","execution":{"iopub.status.busy":"2022-04-12T09:28:48.974338Z","iopub.execute_input":"2022-04-12T09:28:48.974802Z","iopub.status.idle":"2022-04-12T09:28:48.984343Z","shell.execute_reply.started":"2022-04-12T09:28:48.974765Z","shell.execute_reply":"2022-04-12T09:28:48.983368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def idxseq2str(idxseq):\n    charseq = []\n    for idx in idxseq:\n        if idx < len(idx2char):\n            charseq.append(idx2char[idx])\n        else:\n            charseq.append(' ')\n    return charseq\nprint(''.join(idxseq2str(cuter_idxseq)))","metadata":{"id":"K4mq2CIXlA5o","outputId":"c1c73bee-cc2a-4895-bfdd-dd3fa9bd8000","execution":{"iopub.status.busy":"2022-04-12T09:28:48.985433Z","iopub.execute_input":"2022-04-12T09:28:48.985718Z","iopub.status.idle":"2022-04-12T09:28:48.994722Z","shell.execute_reply.started":"2022-04-12T09:28:48.985684Z","shell.execute_reply":"2022-04-12T09:28:48.99396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sent2data(sent):\n    charidxs = []\n    wordbrks = []\n    for charseq in sent:\n        idxs = str2idxseq(charseq)\n        charidxs.extend(idxs)\n        wordbrks.extend((len(idxs) - 1) * [False] + [True])\n    return (T.tensor(charidxs).cuda(), T.tensor(wordbrks).cuda())","metadata":{"id":"oY13JC7ilHID","execution":{"iopub.status.busy":"2022-04-12T09:28:48.99588Z","iopub.execute_input":"2022-04-12T09:28:48.996655Z","iopub.status.idle":"2022-04-12T09:28:49.003713Z","shell.execute_reply.started":"2022-04-12T09:28:48.996616Z","shell.execute_reply":"2022-04-12T09:28:49.002957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef corpus2dataset(corpus):\n    dataset = []\n    for sent in corpus:\n        charidxs, wordbrks = sent2data(sent)\n        dataset.append((charidxs, wordbrks))\n    return dataset","metadata":{"id":"Qylpe6S9lJa3","execution":{"iopub.status.busy":"2022-04-12T09:28:49.004927Z","iopub.execute_input":"2022-04-12T09:28:49.005235Z","iopub.status.idle":"2022-04-12T09:28:49.014626Z","shell.execute_reply.started":"2022-04-12T09:28:49.005199Z","shell.execute_reply":"2022-04-12T09:28:49.01384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cell 13\ndef corpus2dataset_dl(corpus):\n    dataset = []\n    data = []\n    label = []\n    for sent in corpus:\n        charidxs, wordbrks = sent2data(sent)\n        data.append(charidxs)\n        label.append(wordbrks)\n    return data , label","metadata":{"id":"GzJafUUslMcH","execution":{"iopub.status.busy":"2022-04-12T09:28:49.015681Z","iopub.execute_input":"2022-04-12T09:28:49.016587Z","iopub.status.idle":"2022-04-12T09:28:49.025734Z","shell.execute_reply.started":"2022-04-12T09:28:49.01654Z","shell.execute_reply":"2022-04-12T09:28:49.024982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_train , label_train = corpus2dataset_dl(data_df['tokens'].to_list())\ntrain_val , label_val = corpus2dataset_dl(data_val['tokens'].to_list())\ntrain_test , label_test = corpus2dataset_dl(data_test['tokens'].to_list())","metadata":{"id":"N3RZGKRmlay9","execution":{"iopub.status.busy":"2022-04-12T09:28:49.027122Z","iopub.execute_input":"2022-04-12T09:28:49.027578Z","iopub.status.idle":"2022-04-12T09:29:05.571834Z","shell.execute_reply.started":"2022-04-12T09:28:49.027534Z","shell.execute_reply":"2022-04-12T09:29:05.571024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Mydataset(Dataset):\n    def __init__(self, train, label):\n        self.train = train\n        self.label = label\n\n    def __len__(self):\n        return len(self.train)\n\n    def __getitem__(self, idx):\n        return self.train[idx],self.label[idx]","metadata":{"id":"_QiYGvLnluFm","execution":{"iopub.status.busy":"2022-04-12T09:29:05.573087Z","iopub.execute_input":"2022-04-12T09:29:05.57379Z","iopub.status.idle":"2022-04-12T09:29:05.579719Z","shell.execute_reply.started":"2022-04-12T09:29:05.573746Z","shell.execute_reply":"2022-04-12T09:29:05.578952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def colletefn(bat):\n    a=[]\n    b=[]\n    for i in bat:\n        a.append(i[0])\n        b.append(i[1])\n    a = T.cat(a)\n    b = T.cat(b)\n    return a,b\n","metadata":{"id":"TuPr9617lzRx","execution":{"iopub.status.busy":"2022-04-12T09:29:05.58118Z","iopub.execute_input":"2022-04-12T09:29:05.581838Z","iopub.status.idle":"2022-04-12T09:29:05.589646Z","shell.execute_reply.started":"2022-04-12T09:29:05.581792Z","shell.execute_reply":"2022-04-12T09:29:05.588997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = Mydataset(train=train_train,label=label_train) \ndataset_val = Mydataset(train=train_val,label=label_val) \ndataset_test = Mydataset(train=train_test,label=label_test) ","metadata":{"id":"eqTmHg_8mLZf","execution":{"iopub.status.busy":"2022-04-12T09:29:05.59075Z","iopub.execute_input":"2022-04-12T09:29:05.591056Z","iopub.status.idle":"2022-04-12T09:29:05.598033Z","shell.execute_reply.started":"2022-04-12T09:29:05.59102Z","shell.execute_reply":"2022-04-12T09:29:05.597321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset_train, batch_size=256, shuffle=True, collate_fn=colletefn)\nval_loader = DataLoader(dataset_val,batch_size=256, shuffle=True, collate_fn=colletefn)\ntest_loader = DataLoader(dataset_test, batch_size=256 ,shuffle=True, collate_fn=colletefn)","metadata":{"id":"rK4qrl9ZmR6q","execution":{"iopub.status.busy":"2022-04-12T09:29:05.599238Z","iopub.execute_input":"2022-04-12T09:29:05.59951Z","iopub.status.idle":"2022-04-12T09:29:05.606808Z","shell.execute_reply.started":"2022-04-12T09:29:05.599452Z","shell.execute_reply":"2022-04-12T09:29:05.606118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def wordbrks2brkvec(wordbrks):\n    return wordbrks.bool().long()\n    brkvec = T.LongTensor(len(wordbrks))\n    for i in range(len(wordbrks)):\n        if wordbrks[i]: brkvec[i] = 0\n        else: brkvec[i] = 1\n    return brkvec.cuda()\n\n#cell 19","metadata":{"id":"tUBRp6pf1QzB","execution":{"iopub.status.busy":"2022-04-12T09:29:05.608068Z","iopub.execute_input":"2022-04-12T09:29:05.608443Z","iopub.status.idle":"2022-04-12T09:29:05.615056Z","shell.execute_reply.started":"2022-04-12T09:29:05.608407Z","shell.execute_reply":"2022-04-12T09:29:05.614382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"T.cuda.is_available()","metadata":{"id":"1LfoPUNE6Aoj","outputId":"1ab1f16d-3fd6-4471-c737-ad2008c35404","execution":{"iopub.status.busy":"2022-04-12T09:29:05.616903Z","iopub.execute_input":"2022-04-12T09:29:05.61739Z","iopub.status.idle":"2022-04-12T09:29:05.62589Z","shell.execute_reply.started":"2022-04-12T09:29:05.617354Z","shell.execute_reply":"2022-04-12T09:29:05.625185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WordsegModel(N.Module):\n    def __init__(self, dim_charvec, dim_trans, no_layers):\n        super(WordsegModel, self).__init__()\n        self._dim_charvec = dim_charvec\n        self._dim_trans = dim_trans\n        self._no_layers = no_layers\n        \n        self._charemb = N.Embedding(184, self._dim_charvec)\n        \n        self._rnn = N.GRU(\n            self._dim_charvec, self._dim_trans, self._no_layers,\n            batch_first=True, bidirectional=True ,dropout=0.2\n        )\n\n        self._tanh = N.Tanh()\n        self._hidden = N.Linear(2 * self._dim_trans, 2)    # Predicting two classes: break / no break\n        self._log_softmax = N.LogSoftmax(dim=1)\n        \n    def forward(self, charidxs):\n        # try:\n            charvecs = self._charemb(T.as_tensor(charidxs,device='cuda'))\n            # print('charvecs =\\n{}'.format(charvecs))\n            ctxvecs, lasthids = self._rnn(charvecs.unsqueeze(0))\n            ctxvecs, lasthids = ctxvecs.squeeze(0), lasthids.squeeze(1)\n            # print('ctxvecs =\\n{}'.format(ctxvecs))\n            statevecs = self._hidden(self._tanh(ctxvecs))\n            # print('statevecs =\\n{}'.format(statevecs))\n            brkvecs = self._log_softmax(statevecs)\n            # print('brkvecs =\\n{}'.format(brkvecs))\n            return brkvecs\n        # except RuntimeError:\n        #     raise RuntimeError(statevecs)\n\n#cell 21","metadata":{"id":"jG4l-Bw46EUL","execution":{"iopub.status.busy":"2022-04-12T09:29:05.627294Z","iopub.execute_input":"2022-04-12T09:29:05.627814Z","iopub.status.idle":"2022-04-12T09:29:05.6377Z","shell.execute_reply.started":"2022-04-12T09:29:05.627717Z","shell.execute_reply":"2022-04-12T09:29:05.636937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def argmax(vec):\n    # return the argmax as a python int\n    _, idx = T.max(vec, 1)\n    return idx.item()\n\n\ndef prepare_sequence(seq, to_ix):\n    idxs = [to_ix[w] for w in seq]\n    return T.tensor(idxs, dtype=T.long)\n\n\n# Compute log sum exp in a numerically stable way for the forward algorithm\ndef log_sum_exp(vec):\n    max_score = vec[0, argmax(vec)]\n    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n    return max_score + \\\n        T.log(T.sum(T.exp(vec - max_score_broadcast)))","metadata":{"id":"ERSP1MxG6_9E","execution":{"iopub.status.busy":"2022-04-12T09:29:05.638987Z","iopub.execute_input":"2022-04-12T09:29:05.639247Z","iopub.status.idle":"2022-04-12T09:29:05.650428Z","shell.execute_reply.started":"2022-04-12T09:29:05.639214Z","shell.execute_reply":"2022-04-12T09:29:05.64978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BiLSTM_CRF(N.Module):\n\n    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n        super(BiLSTM_CRF, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.vocab_size = vocab_size\n        self.tag_to_ix = tag_to_ix\n        self.tagset_size = len(tag_to_ix)\n\n        self.word_embeds = N.Embedding(vocab_size, embedding_dim)\n        self.lstm = N.LSTM(embedding_dim, hidden_dim // 2,\n                            num_layers=1, bidirectional=True)\n\n        # Maps the output of the LSTM into tag space.\n        self.hidden2tag = N.Linear(hidden_dim, self.tagset_size)\n\n        # Matrix of transition parameters.  Entry i,j is the score of\n        # transitioning *to* i *from* j.\n        self.transitions = N.Parameter(\n            torch.randn(self.tagset_size, self.tagset_size))\n\n        # These two statements enforce the constraint that we never transfer\n        # to the start tag and we never transfer from the stop tag\n        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n\n        self.hidden = self.init_hidden()\n\n    def init_hidden(self):\n        return (torch.randn(2, 1, self.hidden_dim // 2),\n                torch.randn(2, 1, self.hidden_dim // 2))\n\n    def _forward_alg(self, feats):\n        # Do the forward algorithm to compute the partition function\n        init_alphas = torch.full((1, self.tagset_size), -10000.)\n        # START_TAG has all of the score.\n        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n\n        # Wrap in a variable so that we will get automatic backprop\n        forward_var = init_alphas\n\n        # Iterate through the sentence\n        for feat in feats:\n            alphas_t = []  # The forward tensors at this timestep\n            for next_tag in range(self.tagset_size):\n                # broadcast the emission score: it is the same regardless of\n                # the previous tag\n                emit_score = feat[next_tag].view(\n                    1, -1).expand(1, self.tagset_size)\n                # the ith entry of trans_score is the score of transitioning to\n                # next_tag from i\n                trans_score = self.transitions[next_tag].view(1, -1)\n                # The ith entry of next_tag_var is the value for the\n                # edge (i -> next_tag) before we do log-sum-exp\n                next_tag_var = forward_var + trans_score + emit_score\n                # The forward variable for this tag is log-sum-exp of all the\n                # scores.\n                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n            forward_var = torch.cat(alphas_t).view(1, -1)\n        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n        alpha = log_sum_exp(terminal_var)\n        return alpha\n\n    def _get_lstm_features(self, sentence):\n        self.hidden = self.init_hidden()\n        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n        lstm_feats = self.hidden2tag(lstm_out)\n        return lstm_feats\n\n    def _score_sentence(self, feats, tags):\n        # Gives the score of a provided tag sequence\n        score = torch.zeros(1)\n        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n        for i, feat in enumerate(feats):\n            score = score + \\\n                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n        return score\n\n    def _viterbi_decode(self, feats):\n        backpointers = []\n\n        # Initialize the viterbi variables in log space\n        init_vvars = torch.full((1, self.tagset_size), -10000.)\n        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n\n        # forward_var at step i holds the viterbi variables for step i-1\n        forward_var = init_vvars\n        for feat in feats:\n            bptrs_t = []  # holds the backpointers for this step\n            viterbivars_t = []  # holds the viterbi variables for this step\n\n            for next_tag in range(self.tagset_size):\n                # next_tag_var[i] holds the viterbi variable for tag i at the\n                # previous step, plus the score of transitioning\n                # from tag i to next_tag.\n                # We don't include the emission scores here because the max\n                # does not depend on them (we add them in below)\n                next_tag_var = forward_var + self.transitions[next_tag]\n                best_tag_id = argmax(next_tag_var)\n                bptrs_t.append(best_tag_id)\n                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n            # Now add in the emission scores, and assign forward_var to the set\n            # of viterbi variables we just computed\n            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n            backpointers.append(bptrs_t)\n\n        # Transition to STOP_TAG\n        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n        best_tag_id = argmax(terminal_var)\n        path_score = terminal_var[0][best_tag_id]\n\n        # Follow the back pointers to decode the best path.\n        best_path = [best_tag_id]\n        for bptrs_t in reversed(backpointers):\n            best_tag_id = bptrs_t[best_tag_id]\n            best_path.append(best_tag_id)\n        # Pop off the start tag (we dont want to return that to the caller)\n        start = best_path.pop()\n        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n        best_path.reverse()\n        return path_score, best_path\n\n    def neg_log_likelihood(self, sentence, tags):\n        feats = self._get_lstm_features(sentence)\n        forward_score = self._forward_alg(feats)\n        gold_score = self._score_sentence(feats, tags)\n        return forward_score - gold_score\n\n    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n        # Get the emission scores from the BiLSTM\n        lstm_feats = self._get_lstm_features(sentence)\n\n        # Find the best path, given the features.\n        score, tag_seq = self._viterbi_decode(lstm_feats)\n        return score, tag_seq","metadata":{"id":"Zd6CjAns67mp","execution":{"iopub.status.busy":"2022-04-12T09:29:05.652055Z","iopub.execute_input":"2022-04-12T09:29:05.652649Z","iopub.status.idle":"2022-04-12T09:29:05.67882Z","shell.execute_reply.started":"2022-04-12T09:29:05.652609Z","shell.execute_reply":"2022-04-12T09:29:05.677986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndevice = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"v0fczXH96SR_","outputId":"d329c946-adbb-4409-b726-5f0efd4cd698","execution":{"iopub.status.busy":"2022-04-12T09:29:05.680035Z","iopub.execute_input":"2022-04-12T09:29:05.680769Z","iopub.status.idle":"2022-04-12T09:29:05.694894Z","shell.execute_reply.started":"2022-04-12T09:29:05.680726Z","shell.execute_reply":"2022-04-12T09:29:05.694076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install gdown\n# !gdown --id 10ehc_ARUyzkWycJekS51_bIdzU3exBSQ","metadata":{"execution":{"iopub.status.busy":"2022-04-12T09:29:05.696049Z","iopub.execute_input":"2022-04-12T09:29:05.696456Z","iopub.status.idle":"2022-04-12T09:29:30.886764Z","shell.execute_reply.started":"2022-04-12T09:29:05.696409Z","shell.execute_reply":"2022-04-12T09:29:30.885878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = WordsegModel(32,256,4).to(device=device)\nmodel","metadata":{"id":"i9t_oESH6UA7","execution":{"iopub.status.busy":"2022-04-12T09:32:40.777854Z","iopub.execute_input":"2022-04-12T09:32:40.778118Z","iopub.status.idle":"2022-04-12T09:32:40.822834Z","shell.execute_reply.started":"2022-04-12T09:32:40.778089Z","shell.execute_reply":"2022-04-12T09:32:40.82193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(wordseg_model, training_data, val_data,epochs, loss_fn, optimizer):\n    no_samples = len(training_data)\n    loss_history = []\n    no_val = len(val_data)\n    val_loss_his = []\n    \n    for i in range(epochs):\n        total_loss = 0.0\n        # random.shuffle(training_data)\n        v_loss = 0.0\n        # random.shuffle(val_data)\n        for charidxs, wordbrks in tqdm(training_data):   \n            # charidxs = T.flatten(charidxs)\n            # wordbrks = T.flatten(wordbrks)\n            pred_brkvecs = wordseg_model(charidxs)       # Perform prediction\n            gold_brkvec = wordbrks2brkvec(wordbrks)      # Gold standard\n            pred_brkvecs = pred_brkvecs.cuda()\n            # print(gold_brkvec)\n\n            loss = loss_fn(pred_brkvecs, gold_brkvec)\n            loss.cuda()\n            total_loss += loss.item()\n            \n            optimizer.zero_grad()      # Clear gradient cache\n            loss.backward()            # Perform backpropagation\n            optimizer.step()           # Update the model parameters\n        for (charidxs, wordbrks) in tqdm(val_data):   \n        \n            pred_brkvecs = wordseg_model(charidxs)       # Perform prediction\n\n            gold_brkvec = wordbrks2brkvec(wordbrks)      # Gold standard\n\n            lossv = loss_fn(pred_brkvecs, gold_brkvec)\n            v_loss += lossv.item()\n\n        \n        # wandb.log({\"loss\": total_loss / no_samples})\n        print(\"epochs {}   Loss: {}  val_loss: {}\".format(i+1,(total_loss / no_samples),(v_loss/no_samples)))\n        # sentline(\"epochs {}\\nLoss: {}  \\nval_loss: {}\".format(i+1,(total_loss / no_samples),(v_loss/no_samples)))\n        loss_history.append(total_loss / no_samples)\n        val_loss_his.append(v_loss / no_val)\n        T.save(wordseg_model.state_dict(), 'best_{}.pt'.format(i+1))\n    # epoch_count = range(1, epochs + 1)\n    # plt.plot(epoch_count, loss_history, 'b--')\n    # plt.plot(epoch_count, val_loss_his, 'r')\n    # plt.legend(['Training Loss'])\n    # plt.xlabel('Epoch')\n    # plt.ylabel('Loss')\n    # plt.show()\n\n    return loss_history\n\n","metadata":{"id":"EIgjEdblAJUR","execution":{"iopub.status.busy":"2022-04-12T09:32:43.572356Z","iopub.execute_input":"2022-04-12T09:32:43.572707Z","iopub.status.idle":"2022-04-12T09:32:43.582447Z","shell.execute_reply.started":"2022-04-12T09:32:43.572646Z","shell.execute_reply":"2022-04-12T09:32:43.581524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cell 24\nlearning_rate = 0.01\nepochs = 20\n\n# wordseg_model = wordseg_model.cuda()\nloss_fn = N.NLLLoss()\noptimizer = O.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n\nloss_history = train_model(model, train_loader, val_loader,epochs, loss_fn, optimizer)\n\nT.save(model.state_dict(), 'best_final.pt')\n\n#cell 25","metadata":{"id":"TErJfrXY6XiM","outputId":"78f03f59-3a1b-4648-c6ef-123538e5cda6","execution":{"iopub.status.busy":"2022-04-12T09:32:44.238263Z","iopub.execute_input":"2022-04-12T09:32:44.238552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"9hYKOsU16ZeI"},"execution_count":null,"outputs":[]}]}